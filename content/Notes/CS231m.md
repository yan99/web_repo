---
title: Stanford CS 231m
description: Part of Notes for Course Mobile Computer Vision
math: true
---

## Panoramas
Can be achieved with wide-angle optics or rotation cameras.
 ### System Overview
 - Camera Module -> Video Frames -> Real-Time Tracking -> Camera Module
 - Camera Module -> Images -> Warping -> Registration -> Blending -> Final Panorama
 ### Cylindrical Panoramas
 - Project each image onto a cylinder
 - A cylindrical image is a rectangular array
 - View: reproject a portion of the cylinder onto a picture plane representing the display screen
 - Narrow FOV -> less distortion
 - Same center of projection.
 ### Stitching
 Detect key points -> find corresponding pairs -> align images
 #### Key Points
   - Harris corner detector: $$E(u,v) = \sum_{x, y}w(x,y)[I(x+u,y+v)-I(x,y)]^{2}$$, where $w(x,y)$ is window function
   - Measure of corner response: $$M = \sum_{x,y}w(x,y)\begin{bmatrix} I_{x}^{2} & I_{x}I_{y} // I_{x}I_{y} & I_{y}^{2} \end{bmatrix}$$
   - Both $\lambda_{1}$ and $\lambda_{2}$ are not too large 
   - $R = det(M) - k(trace(M))^{2}$, $k = 0.04~0.06$, $R>0$ but not small
   - Harris corner detector Workflow: corner response $R$ -> thresholding -> local maxima
   - FAST corners: look for a continuous arc of N pixels, all much darker/brighter than center pixel
 ### Point Descriptors
 Invariant and distinctive
   - SIFT
   - SURF
 ### Blending
 ### Issue: Drift 
 - Vertical error accumulation <- Apply correction make zero sum in vertical displacement
 - Horizontal error accumulation <- Reuse 1st/last image for right panorama radius
 ### Registration
 - Gradients along vertical, horizontal, diagonals -> corners as key points
 - Match gradient projections and determine transition
 - Apply transition to corners -> match corners -> regine transition and rotation

## HDR Imaging
 ### Dynamic Range
 - $cd/m^{2} = lux$
 	* Eye can adapt from $10^{-6}$ to $10^{8} cd/m^{2}$
 	* without adaptation from $1$ to $10^{4} cd/m^{2}$
 	* with non-specular reflectance from $1$ to $10^{3} cd/m^{2}$
 	* Display: $1$ to $100 cd/m^{2}$ (0-255)
 ### HDR Previous Methods
 - Human HDR: sensitive to contrast (log scale); pupil; neural & chemical; transmition to brain
 - Multiple exposure photography: map segments of high dynamic range to low contrasts
 - Camera response curve calibration for the multiple images with various exposure time: adjust radiance to obtain a smooth response curve
 - Dodging and burning: hide partial during exposure; exposure more to a region; smooth circular motions & blurry mask avoid artifacts
 - Gamma correction
 - Global tone mapping (various contrast for each image)
 - Local tone mapping (Reinhard operator to avoid high light satrurated)
 - Hitogram adjustment: lum not even -> equalization, histogram in log space -> issue: expand comtrast -> trimming large bins (adjustment)
 - Oppenheim: low contrast on low-freq, keep high-freq -> issue: halo -> bilateral filtering on intensity
 - Exposure fusion: weights over 3 maps: Laplacian filter -> contrast map; saturation on RGB respectively; exposure stretched based on gaussian distribution
 - Multi-resolution fusion: Laplacian pyramid $*$ Gaussian Pyramid generate fused pyramid 
 - HDR video: auto exposure, motion compensation (registration between frames), tone mapping
 ### System Overview
 Reference frame selection -> consistency detection -> HDR generation -> Poisson blending
 ### HDR optical system
 - Beam splitting prism breaks up the light into three parts, one for each sensor fitted with different filters
 - With 2 beam splitters instead of prism to increase the light efficiency
## Camera ISP